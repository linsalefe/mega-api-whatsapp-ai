import streamlit as st
import os
from datetime import datetime
import json
from dotenv import load_dotenv
import shutil
import pytz

# Langchain imports for RAG
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from openai import AuthenticationError, APIError # <--- IMPORTE ESTES ERROS ESPEC√çFICOS

# --- Configura√ß√£o Inicial e Vari√°veis de Ambiente ---
load_dotenv()

# Define o fuso hor√°rio de Bras√≠lia para exibi√ß√£o de hora
brazilia_tz = pytz.timezone('America/Sao_Paulo')

# --- VALIDA√á√ÉO E INICIALIZA√á√ÉO CR√çTICA DE OPENAI (MOVENDO PARA O TOPO E GLOBAL) ---
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    st.error("‚ö†Ô∏è ERRO CR√çTICO: OPENAI_API_KEY n√£o encontrada! Por favor, configure-a nas vari√°veis de ambiente do Render (Environment Variables).")
    st.stop() # Parar o Streamlit imediatamente e de forma limpa

try:
    # Tenta inicializar os embeddings globalmente e verifica a chave
    GLOBAL_OPENAI_EMBEDDINGS = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=OPENAI_API_KEY)
    
    # Voc√™ pode adicionar uma pequena chamada de teste aqui se quiser, mas a pr√≥pria inicializa√ß√£o
    # do OpenAIEmbeddings j√° dispara AuthenticationError para chaves inv√°lidas na maioria dos casos.
    # Ex: GLOBAL_OPENAI_EMBEDDINGS.embed_query("warm up") 

except (AuthenticationError, APIError) as e:
    st.error(f"‚ùå ERRO CR√çTICO: Falha de autentica√ß√£o/API com OpenAI Embeddings. Sua OPENAI_API_KEY pode ser inv√°lida ou h√° um problema de conex√£o: {e}")
    st.stop() # Parar o Streamlit imediatamente em caso de erro de API
except Exception as e:
    st.error(f"‚ùå ERRO CR√çTICO: Erro inesperado ao inicializar OpenAI Embeddings: {e}")
    st.stop() # Parar o Streamlit imediatamente em qualquer outro erro

# Inicializa o modelo de chat tamb√©m de forma robusta e global
try:
    GLOBAL_CHAT_MODEL = ChatOpenAI(
        model="gpt-3.5-turbo", # Pode ser mudado para gpt-4o-mini ou gpt-4o
        temperature=0.7,
        api_key=OPENAI_API_KEY
    )
except (AuthenticationError, APIError) as e:
    st.error(f"‚ùå ERRO CR√çTICO: Falha de autentica√ß√£o/API com OpenAI Chat Model. Sua OPENAI_API_KEY pode ser inv√°lida ou h√° um problema de conex√£o: {e}")
    st.stop()
except Exception as e:
    st.error(f"‚ùå ERRO CR√çTICO: Erro inesperado ao inicializar OpenAI Chat Model: {e}")
    st.stop()

# Agora, GLOBAL_OPENAI_EMBEDDINGS e GLOBAL_CHAT_MODEL est√£o garantidos de estarem inicializados e funcionais.

# --- Configura√ß√£o da P√°gina Streamlit e Estilos ---
st.set_page_config(
    page_title="WhatsApp AI Agent - RAG System",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ... (Resto do CSS e fun√ß√µes de utilidade - sem altera√ß√µes aqui) ...

def safe_initialize_chroma():
    """Inicializa o vectorstore do Chroma de forma segura"""
    try:
        if not os.path.exists("./chroma_db"):
            os.makedirs("./chroma_db")
            
        vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=GLOBAL_OPENAI_EMBEDDINGS # <--- USAR O GLOBAL AQUI
        )
        
        try:
            count = vectorstore._collection.count()
            if count == 0:
                st.info("üìö Base de conhecimento vazia. Fa√ßa upload de arquivos para treinar a IA!")
        except Exception as inner_e: 
            st.info(f"üìö Base de conhecimento inicializada mas com erro ao contar cole√ß√£o. Pronta para receber documentos! ({inner_e})")
            
        return vectorstore
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Tentando criar/reiniciar base de conhecimento... ({str(e)})")
        if os.path.exists("./chroma_db"):
            shutil.rmtree("./chroma_db")
            st.info("Diret√≥rio chroma_db removido devido a erro.")
        os.makedirs("./chroma_db")
        
        try:
            vectorstore = Chroma(
                persist_directory="./chroma_db", 
                embedding_function=GLOBAL_OPENAI_EMBEDDINGS # <--- USAR O GLOBAL AQUI
            )
            st.success("‚úÖ Nova base de conhecimento criada com sucesso!")
            return vectorstore
        except Exception as retry_e:
            st.error(f"‚ùå Falha cr√≠tica ao criar nova base de conhecimento ap√≥s erro: {retry_e}. O aplicativo n√£o pode continuar sem um sistema de embeddings funcional.")
            st.stop() # Parar se a inicializa√ß√£o da base falhar totalmente

# --- Fun√ß√µes de Inicializa√ß√£o e L√≥gica do RAG (continuando) ---

def init_openai():
    # Esta fun√ß√£o agora retorna o modelo de chat global, j√° inicializado e validado
    return GLOBAL_CHAT_MODEL

def create_new_knowledge_base(uploaded_files, persist_directory):
    """Cria uma nova base de conhecimento com os documentos fornecidos."""
    with st.spinner("üîÑ Criando nova base de conhecimento..."):
        os.makedirs("uploaded_files", exist_ok=True)
        saved_files = []
        
        for uploaded_file in uploaded_files:
            file_path = os.path.join("uploaded_files", uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            saved_files.append(file_path)
        
        documents = []
        for file_path in saved_files:
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            elif file_path.endswith('.txt'):
                loader = TextLoader(file_path)
            documents.extend(loader.load())
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_documents(documents)
        
        # USAR O EMBEDDING GLOBAL AQUI
        embeddings = GLOBAL_OPENAI_EMBEDDINGS 
        
        if os.path.exists(persist_directory):
            shutil.rmtree(persist_directory)
        
        vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory)
        
        show_notification(f"Base de conhecimento criada com {len(chunks)} chunks!", "success")
        st.rerun()

def process_and_add_documents(uploaded_files, vectorstore, persist_directory):
    """Adiciona novos documentos a uma base de conhecimento existente."""
    with st.spinner("‚ûï Adicionando documentos √† base existente..."):
        os.makedirs("uploaded_files", exist_ok=True)
        saved_files = []
        
        for uploaded_file in uploaded_files:
            file_path = os.path.join("uploaded_files", uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            saved_files.append(file_path)
        
        documents = []
        for file_path in saved_files:
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            elif file_path.endswith('.txt'):
                loader = TextLoader(file_path)
            documents.extend(loader.load())
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_documents(documents)
        
        vectorstore.add_documents(chunks) 
        
        show_notification(f"{len(chunks)} novos chunks adicionados √† base!", "success")
        st.rerun()

# --- P√°ginas da Aplica√ß√£o (continuando) ---

def dashboard_page():
    st.markdown('<h2 class="section-title fade-in">üìä Dashboard Principal</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <h3 class="card-title">‚è∞ Hora Atual do Sistema</h3>
    """, unsafe_allow_html=True)
    
    utc_now = datetime.utcnow()
    bras_now = utc_now.replace(tzinfo=pytz.utc).astimezone(brazilia_tz)
    
    col_time1, col_time2 = st.columns(2)
    with col_time1:
        st.markdown(f"**UTC:** {utc_now.strftime('%d/%m/%Y %H:%M:%S')} (UTC)")
    with col_time2:
        st.markdown(f"**Bras√≠lia:** {bras_now.strftime('%d/%m/%Y %H:%M:%S')} (UTC-3)")
    
    st.markdown("</div>", unsafe_allow_html=True)

    persist_directory = "./chroma_db"
    db_status = "N√£o Inicializado"
    chunk_count = 0
    status_type = "offline"
    
    if os.path.exists(persist_directory) and os.listdir(persist_directory):
        try:
            # USAR O EMBEDDING GLOBAL AQUI
            vectorstore = Chroma(persist_directory=persist_directory, embedding_function=GLOBAL_OPENAI_EMBEDDINGS)
            collection = vectorstore._collection
            chunk_count = collection.count()
            db_status = "Online"
            status_type = "online"
        except Exception as e:
            st.error(f"Erro ao carregar base de conhecimento: {e}. Tentando recriar ou avisar...")
            shutil.rmtree(persist_directory, ignore_errors=True) 
            db_status = "Erro"
            status_type = "warning"
            st.warning("Base de conhecimento corrompida ou n√£o carregada. Por favor, crie uma nova base na se√ß√£o 'Documentos'.")

    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        create_metric_card("156", "Conversas Hoje", change=12, icon="üí¨", progress=78)
    
    with col2:
        create_metric_card("98.5%", "Taxa de Sucesso", change=2, icon="üéØ", progress=98)
    
    with col3:
        create_metric_card("2.3s", "Tempo Resposta", change=-5, icon="‚ö°", progress=85)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card fade-in">
            <div class="metric-header">
                <div>
                    <div class="metric-value">
                        <span class="status-indicator status-{status_type}">
                            ‚óè {db_status}
                        </span>
                    </div>
                    <div class="metric-label">Status RAG</div>
                    <div style="font-size: 0.8rem; color: var(--neutral-700); margin-top: 0.5rem;">
                        {chunk_count} chunks carregados
                    </div>
                </div>
                <div class="metric-icon">ü§ñ</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown('<h3 class="section-title">üîß Status do Sistema</h3>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="feature-card slide-in-left">
            <span class="feature-icon">üü¢</span>
            <h3 class="card-title">WhatsApp API</h3>
            <p class="card-subtitle">Conectado e funcionando perfeitamente</p>
            <div class="status-indicator status-online">
                ‚óè Sistema Operacional
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        status_class = "online" if chunk_count > 0 else "offline"
        status_icon = "üü¢" if chunk_count > 0 else "üî¥"
        status_text = f"Base com {chunk_count} chunks" if chunk_count > 0 else "Base n√£o inicializada"
        
        st.markdown(f"""
        <div class="feature-card slide-in-right">
            <span class="feature-icon">{status_icon}</span>
            <h3 class="card-title">Sistema RAG</h3>
            <p class="card-subtitle">{status_text}</p>
            <div class="status-indicator status-{status_class}">
                ‚óè {db_status}
            </div>
        </div>
        """, unsafe_allow_html=True)

def documents_page():
    st.markdown('<h2 class="section-title fade-in">üìÑ Gerenciamento de Documentos</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Gerencie a base de conhecimento do seu Agente AI. Fa√ßa upload de arquivos PDF e TXT 
            para que a IA possa consult√°-los para responder √†s perguntas.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    persist_directory = "./chroma_db"
    
    # USAR O EMBEDDING GLOBAL AQUI
    embeddings_openai = GLOBAL_OPENAI_EMBEDDINGS

    if os.path.exists(persist_directory) and os.listdir(persist_directory):
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="display: flex; align-items: center; gap: 1rem;">
                <span style="font-size: 2rem;">‚úÖ</span>
                <div>
                    <h3 class="card-title" style="margin: 0;">Base de Conhecimento Ativa</h3>
                    <p class="card-subtitle" style="margin: 0;">Sistema carregado e funcionando</p>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            # USAR O EMBEDDING GLOBAL AQUI
            vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings_openai)
            collection = vectorstore._collection
            count = collection.count()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-header">
                    <div>
                        <div class="metric-value">{count}</div>
                        <div class="metric-label">Chunks de Texto</div>
                    </div>
                    <div class="metric-icon">üìö</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown('<h3 class="section-title">‚ûï Adicionar Mais Documentos</h3>', unsafe_allow_html=True)
            
            uploaded_files = st.file_uploader(
                "Escolha arquivos para adicionar √† base existente",
                type=['pdf', 'txt'],
                accept_multiple_files=True,
                key="add_docs_uploader"
            )
            
            if uploaded_files and st.button("üöÄ Processar e Adicionar Documentos", key="process_add_button"):
                process_and_add_documents(uploaded_files, vectorstore, persist_directory)

        except Exception as e:
            st.error(f"‚ö†Ô∏è Erro ao carregar base de conhecimento existente: {e}. A base pode estar corrompida. Recomenda-se resetar ou criar uma nova.")
            st.markdown("""
            <div class="glass-card fade-in">
                <div style="text-align: center; padding: 2rem;">
                    <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">‚ùå</span>
                    <h3 class="card-title">Erro na Base de Conhecimento</h3>
                    <p class="card-subtitle">
                        N√£o foi poss√≠vel carregar a base de conhecimento existente. Por favor, 
                        considere resetar a base e criar uma nova.
                    </p>
                </div>
            </div>
            """, unsafe_allow_html=True)
            vectorstore = None
            
        st.markdown('<h3 class="section-title">üóëÔ∏è Gerenciamento da Base</h3>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="glass-card">
            <div style="display: flex; align-items: center; gap: 1rem; margin-bottom: 1rem;">
                <span style="font-size: 2rem;">‚ö†Ô∏è</span>
                <div>
                    <h4 style="color: var(--accent-orange); margin: 0;">Zona de Perigo</h4>
                    <p style="margin: 0; color: var(--neutral-700);">
                        Resetar a base ir√° apagar <strong>todos</strong> os documentos indexados
                    </p>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        col_reset1, col_reset2 = st.columns([0.7, 0.3])
        with col_reset1:
            confirm_reset = st.checkbox("Confirmo que quero deletar toda a base de conhecimento", key="confirm_reset_checkbox")
        with col_reset2:
            if st.button("üóëÔ∏è Resetar Base", type="secondary", disabled=not confirm_reset, key="reset_button"):
                shutil.rmtree(persist_directory, ignore_errors=True)
                show_notification("Base de conhecimento resetada!", "success")
                st.rerun()
    
    else:
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="text-align: center; padding: 2rem;">
                <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">üÜï</span>
                <h3 class="card-title">Primeira Configura√ß√£o</h3>
                <p class="card-subtitle">
                    Nenhuma base de conhecimento encontrada. Fa√ßa upload de documentos 
                    para criar a primeira base de conhecimento do seu Agente AI.
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_files = st.file_uploader(
            "Escolha arquivos para criar a base de conhecimento",
            type=['pdf', 'txt'],
            accept_multiple_files=True,
            key="create_docs_uploader"
        )
        
        if uploaded_files and st.button("üöÄ Criar Base de Conhecimento", key="create_base_button"):
            create_new_knowledge_base(uploaded_files, persist_directory)

    st.markdown("---")
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">üåê</span>
        <h3 class="card-title">Scraping de Sites</h3>
        <p class="card-subtitle">Extraia conte√∫do de URLs para a base de conhecimento (em desenvolvimento)</p>
    </div>
    """, unsafe_allow_html=True)
    
    url_input = st.text_input(
        "URL do site para extrair conte√∫do:",
        placeholder="Ex: https://www.anthropic.com/news",
        key="url_input_docs_unique"
    )
    
    if st.button("üîç Extrair Conte√∫do do Site", key="extract_url_button_unique"):
        if url_input:
            st.info(f"üöß Funcionalidade de extra√ß√£o da URL '{url_input}' ser√° implementada nas pr√≥ximas fases.")
        else:
            st.error("‚ùå Por favor, insira uma URL v√°lida.")

def rag_chat_page():
    """P√°gina de Chat melhorada para testar a funcionalidade RAG da IA."""
    st.markdown('<h2 class="section-title fade-in">üí¨ Chat RAG (Teste Inteligente)</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Este √© o ambiente principal para testar as capacidades de resposta do seu Agente AI, 
            utilizando a base de conhecimento que voc√™ carregou. Aqui voc√™ pode fazer perguntas 
            e ver como a IA as responde consultando os documentos.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    persist_directory = "./chroma_db"
    
    # USAR O EMBEDDING GLOBAL AQUI
    embeddings_openai = GLOBAL_OPENAI_EMBEDDINGS

    if not os.path.exists(persist_directory) or not os.listdir(persist_directory):
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="text-align: center; padding: 2rem;">
                <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">‚ö†Ô∏è</span>
                <h3 class="card-title">Base de Conhecimento Necess√°ria</h3>
                <p class="card-subtitle">
                    Nenhuma base de conhecimento encontrada. V√° para a aba 'Documentos' 
                    para criar ou carregar uma e habilitar o chat.
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        return
    
    llm = init_openai() # Esta fun√ß√£o j√° retorna GLOBAL_CHAT_MODEL
    if not llm:
        st.error("üîë O modelo de chat n√£o foi inicializado corretamente. Verifique as configura√ß√µes.")
        return
    
    try:
        # USAR O EMBEDDING GLOBAL AQUI
        vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings_openai)
        
        if vectorstore._collection.count() == 0:
            st.error("‚ö†Ô∏è A base de conhecimento est√° vazia ou corrompida. Por favor, resete-a na se√ß√£o 'Documentos'.")
            return

    except Exception as e:
        st.error(f"‚ö†Ô∏è Erro ao carregar base de conhecimento: {e}. A base pode estar corrompida. Por favor, resete-a na se√ß√£o 'Documentos'.")
        return
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True
    )
    
    st.markdown("""
    <div class="glass-card fade-in">
        <div style="display: flex; align-items: center; gap: 1rem;">
            <span style="font-size: 2rem;">‚úÖ</span>
            <div>
                <h3 class="card-title" style="margin: 0;">Sistema RAG Ativo</h3>
                <p class="card-subtitle" style="margin: 0;">Pronto para responder suas perguntas</p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    if prompt := st.chat_input("üí≠ Fa√ßa uma pergunta sobre os documentos..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("ü§î Analisando documentos..."):
                try:
                    result = qa_chain({"query": prompt})
                    response = result["result"]
                    sources = result["source_documents"]
                    
                    st.markdown(response)
                    
                    if sources: 
                        with st.expander("üìö Fontes Consultadas"):
                            for i, doc in enumerate(sources):
                                st.markdown(f"**üìÑ Documento {i+1}:**")
                                st.code(doc.page_content, language="text")
                                if doc.metadata:
                                    st.json(doc.metadata)
                                if i < len(sources) - 1:
                                    st.markdown("---")
                    
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                except Exception as e:
                    error_msg = f"‚ùå Erro ao processar pergunta: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})

def agent_config_page():
    st.markdown('<h2 class="section-title fade-in">ü§ñ Configura√ß√£o do Agente</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Configure a personalidade e o modelo de IA que o seu Agente utilizar√° para as intera√ß√µes.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="feature-card slide-in-left">
            <span class="feature-icon">üé≠</span>
            <h3 class="card-title">Personalidade</h3>
            <p class="card-subtitle">Configure o tom e estilo do agente</p>
        </div>
        """, unsafe_allow_html=True)
        
        personality = st.selectbox(
            "Escolha a personalidade:",
            ["Profissional", "Amig√°vel", "T√©cnico", "Casual"],
            key="agent_personality_select"
        )
    
    with col2:
        st.markdown("""
        <div class="feature-card slide-in-right">
            <span class="feature-icon">‚ö°</span>
            <h3 class="card-title">Modelo IA</h3>
            <p class="card-subtitle">Selecione o modelo de linguagem</p>
        </div>
        """, unsafe_allow_html=True)
        
        model = st.selectbox(
            "Modelo:",
            ["GPT-3.5-Turbo", "GPT-4o", "Claude 3 Opus", "Gemini Pro"],
            key="agent_model_select"
        )
    
    st.markdown("---")
    
    st.markdown("""
    <div class="glass-card fade-in">
        <h3 class="card-title">üõ†Ô∏è Par√¢metros Avan√ßados do Modelo</h3>
    """, unsafe_allow_html=True)
    
    temperature = st.slider(
        "Temperatura (Criatividade)", 
        min_value=0.0, max_value=1.0, value=0.7, step=0.1,
        help="Um valor mais alto torna as respostas mais criativas"
    )
    
    max_tokens = st.slider(
        "M√°ximo de Tokens na Resposta", 
        min_value=50, max_value=2000, value=500, step=50,
        help="Define o tamanho m√°ximo da resposta gerada pela IA"
    )
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    if st.button("üíæ Salvar Configura√ß√µes do Agente", key="save_agent_config_button"):
        show_notification(f"Configura√ß√µes salvas! Personalidade: {personality}, Modelo: {model}", "success")

def analytics_page():
    st.markdown('<h2 class="section-title fade-in">üìä Analytics e Relat√≥rios</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Acompanhe o desempenho do seu Agente AI com m√©tricas e visualiza√ß√µes 
            sobre as intera√ß√µes e efici√™ncia.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        create_metric_card("1,247", "Total de Conversas", change=15, icon="üí¨", progress=85)
    
    with col2:
        create_metric_card("4.8/5", "Satisfa√ß√£o M√©dia", change=3, icon="‚≠ê", progress=96)
    
    with col3:
        create_metric_card("89%", "Taxa de Resolu√ß√£o", change=7, icon="‚úÖ", progress=89)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="feature-card slide-in-left">
            <span class="feature-icon">üìà</span>
            <h3 class="card-title">Conversas por Hora</h3>
            <p class="card-subtitle">Distribui√ß√£o de conversas ao longo do dia</p>
        </div>
        """, unsafe_allow_html=True)
        
        import pandas as pd
        chart_data = pd.DataFrame({
            'Hora': list(range(24)),
            'Conversas': [5, 3, 2, 1, 2, 4, 8, 15, 25, 30, 35, 40, 45, 42, 38, 35, 40, 45, 35, 25, 20, 15, 10, 8]
        })
        st.line_chart(chart_data.set_index('Hora'))
    
    with col2:
        st.markdown("""
        <div class="feature-card slide-in-right">
            <span class="feature-icon">üéØ</span>
            <h3 class="card-title">Taxa de Resolu√ß√£o</h3>
            <p class="card-subtitle">Percentual de problemas resolvidos automaticamente</p>
        </div>
        """, unsafe_allow_html=True)
        
        resolution_data = pd.DataFrame({
            'Dia': ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'],
            'Taxa': [90, 92, 95, 93, 98, 85, 88]
        })
        st.bar_chart(resolution_data.set_index('Dia'))

    st.markdown("---")
    
    st.markdown("""
    <div class="glass-card fade-in">
        <h3 class="card-title">üìã Relat√≥rios Detalhados</h3>
        <p class="card-subtitle">
            Funcionalidades avan√ßadas de relat√≥rios e exporta√ß√£o de dados ser√£o 
            desenvolvidas nas pr√≥ximas fases do projeto.
        </p>
        <div style="margin-top: 1.5rem;">
            <div style="display: flex; gap: 1rem; flex-wrap: wrap;">
                <div class="status-indicator status-warning">
                    üöß Relat√≥rio Semanal - Em Desenvolvimento
                </div>
                <div class="status-indicator status-warning">
                    üìä Exporta√ß√£o CSV - Em Desenvolvimento
                </div>
                <div class="status-indicator status-warning">
                    üìà Dashboard Avan√ßado - Em Desenvolvimento
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

def settings_page():
    st.markdown('<h2 class="section-title fade-in">‚öôÔ∏è Configura√ß√µes do Sistema</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Aqui voc√™ pode visualizar e configurar informa√ß√µes cruciais sobre o 
            funcionamento do seu Agente AI.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">üîê</span>
        <h3 class="card-title">Chaves de API e Vari√°veis de Ambiente</h3>
        <p class="card-subtitle">
            As chaves de API (como a OPENAI_API_KEY) e outras configura√ß√µes sens√≠veis 
            s√£o carregadas de forma segura do arquivo .env
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    openai_key = os.getenv('OPENAI_API_KEY')
    api_status = "online" if openai_key else "offline"
    api_icon = "üü¢" if openai_key else "üî¥"
    
    st.markdown(f"""
    <div class="glass-card">
        <div style="display: flex; align-items: center; gap: 1rem;">
            <span style="font-size: 2rem;">{api_icon}</span>
            <div>
                <h4 style="margin: 0;">Status da API OpenAI</h4>
                <div class="status-indicator status-{api_status}">
                    ‚óè {'Configurada' if openai_key else 'N√£o Configurada'}
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.code("OPENAI_API_KEY=sua_chave_openai_aqui", language="bash")
    
    with st.expander("üîç Ver Vari√°veis de Ambiente (Debug)"):
        env_vars = {k: "********" if "KEY" in k or "TOKEN" in k else v for k, v in os.environ.items()}
        st.json(dict(list(env_vars.items())[:10]))  
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">üö´</span>
        <h3 class="card-title">Exclus√µes de Arquivos (.gitignore)</h3>
        <p class="card-subtitle">
            O arquivo .gitignore √© crucial para garantir que arquivos desnecess√°rios, 
            tempor√°rios ou sens√≠veis n√£o sejam inclu√≠dos no controle de vers√£o
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("**Conte√∫do sugerido para o seu arquivo `.gitignore`:**")
    st.code("""
# Ambiente Virtual
venv/
env/

# Vari√°veis de Ambiente
.env
.env.local

# Cache Python
__pycache__/
*.pyc
*.pyo
*.pyd

# Logs
logs/
*.log

# Banco de Dados
*.sqlite3
*.db

# Jupyter
.ipynb_checkpoints/

# Sistema
.DS_Store
.idea/
.vscode/

# Build
build/
dist/
*.egg-info/

# Testes
.pytest_cache/
.coverage

# Tempor√°rios
temp/
*.tmp
*.bak

# Chaves e Certificados
*.pem
*.key

# Arquivos do Projeto (Opcional)
uploaded_files/
chroma_db/
    """, language="bash")

    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">üíæ</span>
        <h3 class="card-title">Estrutura de Pastas do Projeto</h3>
        <p class="card-subtitle">
            Verifique se as seguintes pastas e arquivos est√£o organizados para 
            o funcionamento correto do sistema
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.code("""
üìÅ / (Raiz do Projeto)
‚îú‚îÄ‚îÄ üìÑ app.py (Script principal WhatsApp/Flask)
‚îú‚îÄ‚îÄ üìÑ streamlit_app.py (Interface Streamlit)
‚îú‚îÄ‚îÄ  .env (Vari√°veis de ambiente)
‚îú‚îÄ‚îÄ üìÑ .gitignore (Exclus√µes Git)
‚îú‚îÄ‚îÄ üìÑ requirements.txt (Depend√™ncias Python)
‚îú‚îÄ‚îÄ üìÅ venv/ (Ambiente virtual Python)
‚îú‚îÄ‚îÄ üìÅ chroma_db/ (Base de dados vetorial)
‚îú‚îÄ‚îÄ üìÅ uploaded_files/ (Arquivos enviados)
‚îî‚îÄ‚îÄ üìÑ whatsapp_agent.log (Logs do sistema)
    """)

def logs_page():
    st.markdown('<h2 class="section-title fade-in">üìÑ Logs do Sistema</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Monitore as atividades e mensagens do seu Agente AI. Esta se√ß√£o exibe 
            o conte√∫do do arquivo whatsapp_agent.log, que √© gerado pelo seu script 
            de integra√ß√£o do WhatsApp (app.py).
        </p>
    </div>
    """, unsafe_allow_html=True)

    log_file_path = "whatsapp_agent.log"

    if os.path.exists(log_file_path):
        file_size = os.path.getsize(log_file_path)
        file_modified = datetime.fromtimestamp(os.path.getmtime(log_file_path))
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            create_metric_card(f"{file_size} bytes", "Tamanho do Log", icon="üìä")
        
        with col2:
            create_metric_card(file_modified.strftime("%H:%M"), "√öltima Modifica√ß√£o", icon="üïê")
        
        with col3:
            create_metric_card("Online", "Status do Log", icon="üìù")
        
        st.markdown(f"""
        <div class="glass-card fade-in">
            <h3 class="card-title">üìã Conte√∫do de {log_file_path}</h3>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            with open(log_file_path, "r", encoding="utf-8") as f:
                log_content = f.read()
                
            if len(log_content) > 10000:
                log_content = log_content[-10000:] + "\n\n[... mostrando apenas as √∫ltimas 10.000 caracteres]"
                
            st.code(log_content, language="text", height=400)
            
            st.download_button(
                label="üì• Baixar Log Completo",
                data=log_content,
                file_name=f"whatsapp_agent_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain"
            )
            
        except Exception as e:
            st.error(f"‚ùå N√£o foi poss√≠vel ler o arquivo de log: {e}")
    else:
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="text-align: center; padding: 2rem;">
                <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">üìÑ</span>
                <h3 class="card-title">Arquivo de Log N√£o Encontrado</h3>
                <p class="card-subtitle">
                    O arquivo de log whatsapp_agent.log n√£o foi encontrado. 
                    Certifique-se de que o sistema de log do seu app.py esteja 
                    configurado para gravar eventos neste arquivo.
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">üí°</span>
        <h3 class="card-title">Informa√ß√µes sobre Logging</h3>
        <p class="card-subtitle">
            Os logs s√£o ferramentas indispens√°veis para depurar problemas, acompanhar 
            o fluxo de mensagens e monitorar o comportamento geral do agente em produ√ß√£o. 
            √â altamente recomend√°vel configurar seu app.py para registrar eventos importantes.
        </p>
    </div>
    """, unsafe_allow_html=True)

# --- Fun√ß√£o Principal com Navega√ß√£o Melhorada ---
def main():
    st.markdown("""
    <div class="main-header fade-in">
        <h1 class="main-title">ü§ñ WhatsApp AI Agent</h1>
        <p class="main-subtitle">Sistema RAG Inteligente para Atendimento Automatizado</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.sidebar.markdown("""
    <div class="sidebar-header">
        <div class="sidebar-logo">ü§ñ</div>
        <h3 class="sidebar-title">WhatsApp AI</h3>
        <p class="sidebar-subtitle">Sistema RAG Inteligente</p>
    </div>
    """, unsafe_allow_html=True)
    
    pages = {
        "üè† Dashboard": {"func": dashboard_page, "desc": "Vis√£o geral do sistema"},
        "üìÑ Documentos": {"func": documents_page, "desc": "Gerenciar base de conhecimento"},
        "üí¨ Chat RAG": {"func": rag_chat_page, "desc": "Testar sistema inteligente"},
        "ü§ñ Configura√ß√£o": {"func": agent_config_page, "desc": "Configurar agente IA"},
        "üìä Analytics": {"func": analytics_page, "desc": "M√©tricas e relat√≥rios"},
        "‚öôÔ∏è Configura√ß√µes": {"func": settings_page, "desc": "Configura√ß√µes do sistema"},
        "üìÑ Logs": {"func": logs_page, "desc": "Monitorar atividades"}
    }

    selected_page = st.sidebar.radio(
        "Navega√ß√£o Principal:",
        list(pages.keys()),
        format_func=lambda x: x
    )
    
    st.sidebar.markdown(f"""
    <div style="background: rgba(255,255,255,0.1); padding: 1rem; border-radius: 12px; margin: 1rem 0;">
        <small style="color: rgba(255,255,255,0.8);">{pages[selected_page]['desc']}</small>
    </div>
    """, unsafe_allow_html=True)
    
    pages[selected_page]["func"]()

    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style="background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 16px;">
        <h4 style="color: white; margin: 0 0 0.5rem 0;">üë®‚Äçüíª √Ålefe Lins</h4>
        <p style="color: rgba(255,255,255,0.8); font-size: 0.85rem; margin: 0;">
            Profissional intermedi√°rio em IA, focado em estudos e trabalho nas √°reas 
            de marketing e tecnologia.
        </p>
        <div style="margin-top: 1rem; padding-top: 1rem; border-top: 1px solid rgba(255,255,255,0.2);">
            <p style="color: rgba(255,255,255,0.7); font-size: 0.8rem; margin: 0;">
                <strong>Objetivos:</strong> Lan√ßar um aplicativo e iniciar um neg√≥cio de agentes de IA.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.sidebar.markdown("---")
    
    st.sidebar.markdown("""
    <div style="background: rgba(255,255,255,0.05); padding: 1rem; border-radius: 12px;">
        <h5 style="color: white; margin: 0 0 1rem 0;">üöÄ Pr√≥ximos Passos</h5>
        <ul style="color: rgba(255,255,255,0.8); font-size: 0.8rem; margin: 0; padding-left: 1rem;">
            <li>Integra√ß√£o completa RAG + WhatsApp</li>
            <li>Aprimoramento da interface UX/UI</li>
            <li>Automa√ß√£o de respostas inteligentes</li>
            <li>Sistema de analytics avan√ßado</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()