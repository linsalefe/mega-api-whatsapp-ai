import streamlit as st
import os
from datetime import datetime
import json
from dotenv import load_dotenv
import shutil
import pytz

# Langchain imports for RAG
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from openai import AuthenticationError, APIError # <--- IMPORTE ESTES ERROS ESPECÃFICOS

# --- ConfiguraÃ§Ã£o Inicial e VariÃ¡veis de Ambiente ---
load_dotenv()

# Define o fuso horÃ¡rio de BrasÃ­lia para exibiÃ§Ã£o de hora
brazilia_tz = pytz.timezone('America/Sao_Paulo')

# --- VALIDAÃ‡ÃƒO E INICIALIZAÃ‡ÃƒO CRÃTICA DE OPENAI (MOVENDO PARA O TOPO E GLOBAL) ---
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    st.error("âš ï¸ ERRO CRÃTICO: OPENAI_API_KEY nÃ£o encontrada! Por favor, configure-a nas variÃ¡veis de ambiente do Render (Environment Variables).")
    st.stop() # Parar o Streamlit imediatamente e de forma limpa

try:
    # Tenta inicializar os embeddings globalmente e verifica a chave
    GLOBAL_OPENAI_EMBEDDINGS = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=OPENAI_API_KEY)
    
    # VocÃª pode adicionar uma pequena chamada de teste aqui se quiser, mas a prÃ³pria inicializaÃ§Ã£o
    # do OpenAIEmbeddings jÃ¡ dispara AuthenticationError para chaves invÃ¡lidas na maioria dos casos.
    # Ex: GLOBAL_OPENAI_EMBEDDINGS.embed_query("warm up") 

except (AuthenticationError, APIError) as e:
    st.error(f"âŒ ERRO CRÃTICO: Falha de autenticaÃ§Ã£o/API com OpenAI Embeddings. Sua OPENAI_API_KEY pode ser invÃ¡lida ou hÃ¡ um problema de conexÃ£o: {e}")
    st.stop() # Parar o Streamlit imediatamente em caso de erro de API
except Exception as e:
    st.error(f"âŒ ERRO CRÃTICO: Erro inesperado ao inicializar OpenAI Embeddings: {e}")
    st.stop() # Parar o Streamlit imediatamente em qualquer outro erro

# Inicializa o modelo de chat tambÃ©m de forma robusta e global
try:
    GLOBAL_CHAT_MODEL = ChatOpenAI(
        model="gpt-3.5-turbo", # Pode ser mudado para gpt-4o-mini ou gpt-4o
        temperature=0.7,
        api_key=OPENAI_API_KEY
    )
except (AuthenticationError, APIError) as e:
    st.error(f"âŒ ERRO CRÃTICO: Falha de autenticaÃ§Ã£o/API com OpenAI Chat Model. Sua OPENAI_API_KEY pode ser invÃ¡lida ou hÃ¡ um problema de conexÃ£o: {e}")
    st.stop()
except Exception as e:
    st.error(f"âŒ ERRO CRÃTICO: Erro inesperado ao inicializar OpenAI Chat Model: {e}")
    st.stop()

# Agora, GLOBAL_OPENAI_EMBEDDINGS e GLOBAL_CHAT_MODEL estÃ£o garantidos de estarem inicializados e funcionais.

# --- ConfiguraÃ§Ã£o da PÃ¡gina Streamlit e Estilos ---
st.set_page_config(
    page_title="WhatsApp AI Agent - RAG System",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ... (Resto do CSS e funÃ§Ãµes de utilidade - sem alteraÃ§Ãµes aqui) ...

def safe_initialize_chroma():
    """Inicializa o vectorstore do Chroma de forma segura"""
    try:
        if not os.path.exists("./chroma_db"):
            os.makedirs("./chroma_db")
            
        vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=GLOBAL_OPENAI_EMBEDDINGS # <--- USAR O GLOBAL AQUI
        )
        
        try:
            count = vectorstore._collection.count()
            if count == 0:
                st.info("ğŸ“š Base de conhecimento vazia. FaÃ§a upload de arquivos para treinar a IA!")
        except Exception as inner_e: 
            st.info(f"ğŸ“š Base de conhecimento inicializada mas com erro ao contar coleÃ§Ã£o. Pronta para receber documentos! ({inner_e})")
            
        return vectorstore
        
    except Exception as e:
        st.warning(f"âš ï¸ Tentando criar/reiniciar base de conhecimento... ({str(e)})")
        if os.path.exists("./chroma_db"):
            shutil.rmtree("./chroma_db")
            st.info("DiretÃ³rio chroma_db removido devido a erro.")
        os.makedirs("./chroma_db")
        
        try:
            vectorstore = Chroma(
                persist_directory="./chroma_db", 
                embedding_function=GLOBAL_OPENAI_EMBEDDINGS # <--- USAR O GLOBAL AQUI
            )
            st.success("âœ… Nova base de conhecimento criada com sucesso!")
            return vectorstore
        except Exception as retry_e:
            st.error(f"âŒ Falha crÃ­tica ao criar nova base de conhecimento apÃ³s erro: {retry_e}. O aplicativo nÃ£o pode continuar sem um sistema de embeddings funcional.")
            st.stop() # Parar se a inicializaÃ§Ã£o da base falhar totalmente

# --- FunÃ§Ãµes de InicializaÃ§Ã£o e LÃ³gica do RAG (continuando) ---

def init_openai():
    # Esta funÃ§Ã£o agora retorna o modelo de chat global, jÃ¡ inicializado e validado
    return GLOBAL_CHAT_MODEL

def create_new_knowledge_base(uploaded_files, persist_directory):
    """Cria uma nova base de conhecimento com os documentos fornecidos."""
    with st.spinner("ğŸ”„ Criando nova base de conhecimento..."):
        os.makedirs("uploaded_files", exist_ok=True)
        saved_files = []
        
        for uploaded_file in uploaded_files:
            file_path = os.path.join("uploaded_files", uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            saved_files.append(file_path)
        
        documents = []
        for file_path in saved_files:
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            elif file_path.endswith('.txt'):
                loader = TextLoader(file_path)
            documents.extend(loader.load())
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_documents(documents)
        
        # USAR O EMBEDDING GLOBAL AQUI
        embeddings = GLOBAL_OPENAI_EMBEDDINGS 
        
        if os.path.exists(persist_directory):
            shutil.rmtree(persist_directory)
        
        vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory)
        
        show_notification(f"Base de conhecimento criada com {len(chunks)} chunks!", "success")
        st.rerun()

def process_and_add_documents(uploaded_files, vectorstore, persist_directory):
    """Adiciona novos documentos a uma base de conhecimento existente."""
    with st.spinner("â• Adicionando documentos Ã  base existente..."):
        os.makedirs("uploaded_files", exist_ok=True)
        saved_files = []
        
        for uploaded_file in uploaded_files:
            file_path = os.path.join("uploaded_files", uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            saved_files.append(file_path)
        
        documents = []
        for file_path in saved_files:
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            elif file_path.endswith('.txt'):
                loader = TextLoader(file_path)
            documents.extend(loader.load())
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_documents(documents)
        
        vectorstore.add_documents(chunks) 
        
        show_notification(f"{len(chunks)} novos chunks adicionados Ã  base!", "success")
        st.rerun()

# --- PÃ¡ginas da AplicaÃ§Ã£o (continuando) ---

def dashboard_page():
    st.markdown('<h2 class="section-title fade-in">ğŸ“Š Dashboard Principal</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <h3 class="card-title">â° Hora Atual do Sistema</h3>
    """, unsafe_allow_html=True)
    
    utc_now = datetime.utcnow()
    bras_now = utc_now.replace(tzinfo=pytz.utc).astimezone(brazilia_tz)
    
    col_time1, col_time2 = st.columns(2)
    with col_time1:
        st.markdown(f"**UTC:** {utc_now.strftime('%d/%m/%Y %H:%M:%S')} (UTC)")
    with col_time2:
        st.markdown(f"**BrasÃ­lia:** {bras_now.strftime('%d/%m/%Y %H:%M:%S')} (UTC-3)")
    
    st.markdown("</div>", unsafe_allow_html=True)

    persist_directory = "./chroma_db"
    db_status = "NÃ£o Inicializado"
    chunk_count = 0
    status_type = "offline"
    
    if os.path.exists(persist_directory) and os.listdir(persist_directory):
        try:
            # USAR O EMBEDDING GLOBAL AQUI
            vectorstore = Chroma(persist_directory=persist_directory, embedding_function=GLOBAL_OPENAI_EMBEDDINGS)
            collection = vectorstore._collection
            chunk_count = collection.count()
            db_status = "Online"
            status_type = "online"
        except Exception as e:
            st.error(f"Erro ao carregar base de conhecimento: {e}. Tentando recriar ou avisar...")
            shutil.rmtree(persist_directory, ignore_errors=True) 
            db_status = "Erro"
            status_type = "warning"
            st.warning("Base de conhecimento corrompida ou nÃ£o carregada. Por favor, crie uma nova base na seÃ§Ã£o 'Documentos'.")

    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        create_metric_card("156", "Conversas Hoje", change=12, icon="ğŸ’¬", progress=78)
    
    with col2:
        create_metric_card("98.5%", "Taxa de Sucesso", change=2, icon="ğŸ¯", progress=98)
    
    with col3:
        create_metric_card("2.3s", "Tempo Resposta", change=-5, icon="âš¡", progress=85)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card fade-in">
            <div class="metric-header">
                <div>
                    <div class="metric-value">
                        <span class="status-indicator status-{status_type}">
                            â— {db_status}
                        </span>
                    </div>
                    <div class="metric-label">Status RAG</div>
                    <div style="font-size: 0.8rem; color: var(--neutral-700); margin-top: 0.5rem;">
                        {chunk_count} chunks carregados
                    </div>
                </div>
                <div class="metric-icon">ğŸ¤–</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown('<h3 class="section-title">ğŸ”§ Status do Sistema</h3>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="feature-card slide-in-left">
            <span class="feature-icon">ğŸŸ¢</span>
            <h3 class="card-title">WhatsApp API</h3>
            <p class="card-subtitle">Conectado e funcionando perfeitamente</p>
            <div class="status-indicator status-online">
                â— Sistema Operacional
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        status_class = "online" if chunk_count > 0 else "offline"
        status_icon = "ğŸŸ¢" if chunk_count > 0 else "ğŸ”´"
        status_text = f"Base com {chunk_count} chunks" if chunk_count > 0 else "Base nÃ£o inicializada"
        
        st.markdown(f"""
        <div class="feature-card slide-in-right">
            <span class="feature-icon">{status_icon}</span>
            <h3 class="card-title">Sistema RAG</h3>
            <p class="card-subtitle">{status_text}</p>
            <div class="status-indicator status-{status_class}">
                â— {db_status}
            </div>
        </div>
        """, unsafe_allow_html=True)

def documents_page():
    st.markdown('<h2 class="section-title fade-in">ğŸ“„ Gerenciamento de Documentos</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Gerencie a base de conhecimento do seu Agente AI. FaÃ§a upload de arquivos PDF e TXT 
            para que a IA possa consultÃ¡-los para responder Ã s perguntas.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    persist_directory = "./chroma_db"
    
    # USAR O EMBEDDING GLOBAL AQUI
    embeddings_openai = GLOBAL_OPENAI_EMBEDDINGS

    if os.path.exists(persist_directory) and os.listdir(persist_directory):
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="display: flex; align-items: center; gap: 1rem;">
                <span style="font-size: 2rem;">âœ…</span>
                <div>
                    <h3 class="card-title" style="margin: 0;">Base de Conhecimento Ativa</h3>
                    <p class="card-subtitle" style="margin: 0;">Sistema carregado e funcionando</p>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            # USAR O EMBEDDING GLOBAL AQUI
            vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings_openai)
            collection = vectorstore._collection
            count = collection.count()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-header">
                    <div>
                        <div class="metric-value">{count}</div>
                        <div class="metric-label">Chunks de Texto</div>
                    </div>
                    <div class="metric-icon">ğŸ“š</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown('<h3 class="section-title">â• Adicionar Mais Documentos</h3>', unsafe_allow_html=True)
            
            uploaded_files = st.file_uploader(
                "Escolha arquivos para adicionar Ã  base existente",
                type=['pdf', 'txt'],
                accept_multiple_files=True,
                key="add_docs_uploader"
            )
            
            if uploaded_files and st.button("ğŸš€ Processar e Adicionar Documentos", key="process_add_button"):
                process_and_add_documents(uploaded_files, vectorstore, persist_directory)

        except Exception as e:
            st.error(f"âš ï¸ Erro ao carregar base de conhecimento existente: {e}. A base pode estar corrompida. Recomenda-se resetar ou criar uma nova.")
            st.markdown("""
            <div class="glass-card fade-in">
                <div style="text-align: center; padding: 2rem;">
                    <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">âŒ</span>
                    <h3 class="card-title">Erro na Base de Conhecimento</h3>
                    <p class="card-subtitle">
                        NÃ£o foi possÃ­vel carregar a base de conhecimento existente. Por favor, 
                        considere resetar a base e criar uma nova.
                    </p>
                </div>
            </div>
            """, unsafe_allow_html=True)
            vectorstore = None
            
        st.markdown('<h3 class="section-title">ğŸ—‘ï¸ Gerenciamento da Base</h3>', unsafe_allow_html=True)
        
        st.markdown("""
        <div class="glass-card">
            <div style="display: flex; align-items: center; gap: 1rem; margin-bottom: 1rem;">
                <span style="font-size: 2rem;">âš ï¸</span>
                <div>
                    <h4 style="color: var(--accent-orange); margin: 0;">Zona de Perigo</h4>
                    <p style="margin: 0; color: var(--neutral-700);">
                        Resetar a base irÃ¡ apagar <strong>todos</strong> os documentos indexados
                    </p>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        col_reset1, col_reset2 = st.columns([0.7, 0.3])
        with col_reset1:
            confirm_reset = st.checkbox("Confirmo que quero deletar toda a base de conhecimento", key="confirm_reset_checkbox")
        with col_reset2:
            if st.button("ğŸ—‘ï¸ Resetar Base", type="secondary", disabled=not confirm_reset, key="reset_button"):
                shutil.rmtree(persist_directory, ignore_errors=True)
                show_notification("Base de conhecimento resetada!", "success")
                st.rerun()
    
    else:
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="text-align: center; padding: 2rem;">
                <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">ğŸ†•</span>
                <h3 class="card-title">Primeira ConfiguraÃ§Ã£o</h3>
                <p class="card-subtitle">
                    Nenhuma base de conhecimento encontrada. FaÃ§a upload de documentos 
                    para criar a primeira base de conhecimento do seu Agente AI.
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_files = st.file_uploader(
            "Escolha arquivos para criar a base de conhecimento",
            type=['pdf', 'txt'],
            accept_multiple_files=True,
            key="create_docs_uploader"
        )
        
        if uploaded_files and st.button("ğŸš€ Criar Base de Conhecimento", key="create_base_button"):
            create_new_knowledge_base(uploaded_files, persist_directory)

    st.markdown("---")
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">ğŸŒ</span>
        <h3 class="card-title">Scraping de Sites</h3>
        <p class="card-subtitle">Extraia conteÃºdo de URLs para a base de conhecimento (em desenvolvimento)</p>
    </div>
    """, unsafe_allow_html=True)
    
    url_input = st.text_input(
        "URL do site para extrair conteÃºdo:",
        placeholder="Ex: https://www.anthropic.com/news",
        key="url_input_docs_unique"
    )
    
    if st.button("ğŸ” Extrair ConteÃºdo do Site", key="extract_url_button_unique"):
        if url_input:
            st.info(f"ğŸš§ Funcionalidade de extraÃ§Ã£o da URL '{url_input}' serÃ¡ implementada nas prÃ³ximas fases.")
        else:
            st.error("âŒ Por favor, insira uma URL vÃ¡lida.")

def rag_chat_page():
    """PÃ¡gina de Chat melhorada para testar a funcionalidade RAG da IA."""
    st.markdown('<h2 class="section-title fade-in">ğŸ’¬ Chat RAG (Teste Inteligente)</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Este Ã© o ambiente principal para testar as capacidades de resposta do seu Agente AI, 
            utilizando a base de conhecimento que vocÃª carregou. Aqui vocÃª pode fazer perguntas 
            e ver como a IA as responde consultando os documentos.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    persist_directory = "./chroma_db"
    
    # USAR O EMBEDDING GLOBAL AQUI
    embeddings_openai = GLOBAL_OPENAI_EMBEDDINGS

    if not os.path.exists(persist_directory) or not os.listdir(persist_directory):
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="text-align: center; padding: 2rem;">
                <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">âš ï¸</span>
                <h3 class="card-title">Base de Conhecimento NecessÃ¡ria</h3>
                <p class="card-subtitle">
                    Nenhuma base de conhecimento encontrada. VÃ¡ para a aba 'Documentos' 
                    para criar ou carregar uma e habilitar o chat.
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        return
    
    llm = init_openai() # Esta funÃ§Ã£o jÃ¡ retorna GLOBAL_CHAT_MODEL
    if not llm:
        st.error("ğŸ”‘ O modelo de chat nÃ£o foi inicializado corretamente. Verifique as configuraÃ§Ãµes.")
        return
    
    try:
        # USAR O EMBEDDING GLOBAL AQUI
        vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings_openai)
        
        if vectorstore._collection.count() == 0:
            st.error("âš ï¸ A base de conhecimento estÃ¡ vazia ou corrompida. Por favor, resete-a na seÃ§Ã£o 'Documentos'.")
            return

    except Exception as e:
        st.error(f"âš ï¸ Erro ao carregar base de conhecimento: {e}. A base pode estar corrompida. Por favor, resete-a na seÃ§Ã£o 'Documentos'.")
        return
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True
    )
    
    st.markdown("""
    <div class="glass-card fade-in">
        <div style="display: flex; align-items: center; gap: 1rem;">
            <span style="font-size: 2rem;">âœ…</span>
            <div>
                <h3 class="card-title" style="margin: 0;">Sistema RAG Ativo</h3>
                <p class="card-subtitle" style="margin: 0;">Pronto para responder suas perguntas</p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    if prompt := st.chat_input("ğŸ’­ FaÃ§a uma pergunta sobre os documentos..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” Analisando documentos..."):
                try:
                    result = qa_chain({"query": prompt})
                    response = result["result"]
                    sources = result["source_documents"]
                    
                    st.markdown(response)
                    
                    if sources: 
                        with st.expander("ğŸ“š Fontes Consultadas"):
                            for i, doc in enumerate(sources):
                                st.markdown(f"**ğŸ“„ Documento {i+1}:**")
                                st.code(doc.page_content, language="text")
                                if doc.metadata:
                                    st.json(doc.metadata)
                                if i < len(sources) - 1:
                                    st.markdown("---")
                    
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                except Exception as e:
                    error_msg = f"âŒ Erro ao processar pergunta: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})

def agent_config_page():
    st.markdown('<h2 class="section-title fade-in">ğŸ¤– ConfiguraÃ§Ã£o do Agente</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Configure a personalidade e o modelo de IA que o seu Agente utilizarÃ¡ para as interaÃ§Ãµes.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="feature-card slide-in-left">
            <span class="feature-icon">ğŸ­</span>
            <h3 class="card-title">Personalidade</h3>
            <p class="card-subtitle">Configure o tom e estilo do agente</p>
        </div>
        """, unsafe_allow_html=True)
        
        personality = st.selectbox(
            "Escolha a personalidade:",
            ["Profissional", "AmigÃ¡vel", "TÃ©cnico", "Casual"],
            key="agent_personality_select"
        )
    
    with col2:
        st.markdown("""
        <div class="feature-card slide-in-right">
            <span class="feature-icon">âš¡</span>
            <h3 class="card-title">Modelo IA</h3>
            <p class="card-subtitle">Selecione o modelo de linguagem</p>
        </div>
        """, unsafe_allow_html=True)
        
        model = st.selectbox(
            "Modelo:",
            ["GPT-3.5-Turbo", "GPT-4o", "Claude 3 Opus", "Gemini Pro"],
            key="agent_model_select"
        )
    
    st.markdown("---")
    
    st.markdown("""
    <div class="glass-card fade-in">
        <h3 class="card-title">ğŸ› ï¸ ParÃ¢metros AvanÃ§ados do Modelo</h3>
    """, unsafe_allow_html=True)
    
    temperature = st.slider(
        "Temperatura (Criatividade)", 
        min_value=0.0, max_value=1.0, value=0.7, step=0.1,
        help="Um valor mais alto torna as respostas mais criativas"
    )
    
    max_tokens = st.slider(
        "MÃ¡ximo de Tokens na Resposta", 
        min_value=50, max_value=2000, value=500, step=50,
        help="Define o tamanho mÃ¡ximo da resposta gerada pela IA"
    )
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    if st.button("ğŸ’¾ Salvar ConfiguraÃ§Ãµes do Agente", key="save_agent_config_button"):
        show_notification(f"ConfiguraÃ§Ãµes salvas! Personalidade: {personality}, Modelo: {model}", "success")

def analytics_page():
    st.markdown('<h2 class="section-title fade-in">ğŸ“Š Analytics e RelatÃ³rios</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Acompanhe o desempenho do seu Agente AI com mÃ©tricas e visualizaÃ§Ãµes 
            sobre as interaÃ§Ãµes e eficiÃªncia.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        create_metric_card("1,247", "Total de Conversas", change=15, icon="ğŸ’¬", progress=85)
    
    with col2:
        create_metric_card("4.8/5", "SatisfaÃ§Ã£o MÃ©dia", change=3, icon="â­", progress=96)
    
    with col3:
        create_metric_card("89%", "Taxa de ResoluÃ§Ã£o", change=7, icon="âœ…", progress=89)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="feature-card slide-in-left">
            <span class="feature-icon">ğŸ“ˆ</span>
            <h3 class="card-title">Conversas por Hora</h3>
            <p class="card-subtitle">DistribuiÃ§Ã£o de conversas ao longo do dia</p>
        </div>
        """, unsafe_allow_html=True)
        
        import pandas as pd
        chart_data = pd.DataFrame({
            'Hora': list(range(24)),
            'Conversas': [5, 3, 2, 1, 2, 4, 8, 15, 25, 30, 35, 40, 45, 42, 38, 35, 40, 45, 35, 25, 20, 15, 10, 8]
        })
        st.line_chart(chart_data.set_index('Hora'))
    
    with col2:
        st.markdown("""
        <div class="feature-card slide-in-right">
            <span class="feature-icon">ğŸ¯</span>
            <h3 class="card-title">Taxa de ResoluÃ§Ã£o</h3>
            <p class="card-subtitle">Percentual de problemas resolvidos automaticamente</p>
        </div>
        """, unsafe_allow_html=True)
        
        resolution_data = pd.DataFrame({
            'Dia': ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'],
            'Taxa': [90, 92, 95, 93, 98, 85, 88]
        })
        st.bar_chart(resolution_data.set_index('Dia'))

    st.markdown("---")
    
    st.markdown("""
    <div class="glass-card fade-in">
        <h3 class="card-title">ğŸ“‹ RelatÃ³rios Detalhados</h3>
        <p class="card-subtitle">
            Funcionalidades avanÃ§adas de relatÃ³rios e exportaÃ§Ã£o de dados serÃ£o 
            desenvolvidas nas prÃ³ximas fases do projeto.
        </p>
        <div style="margin-top: 1.5rem;">
            <div style="display: flex; gap: 1rem; flex-wrap: wrap;">
                <div class="status-indicator status-warning">
                    ğŸš§ RelatÃ³rio Semanal - Em Desenvolvimento
                </div>
                <div class="status-indicator status-warning">
                    ğŸ“Š ExportaÃ§Ã£o CSV - Em Desenvolvimento
                </div>
                <div class="status-indicator status-warning">
                    ğŸ“ˆ Dashboard AvanÃ§ado - Em Desenvolvimento
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

def settings_page():
    st.markdown('<h2 class="section-title fade-in">âš™ï¸ ConfiguraÃ§Ãµes do Sistema</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Aqui vocÃª pode visualizar e configurar informaÃ§Ãµes cruciais sobre o 
            funcionamento do seu Agente AI.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">ğŸ”</span>
        <h3 class="card-title">Chaves de API e VariÃ¡veis de Ambiente</h3>
        <p class="card-subtitle">
            As chaves de API (como a OPENAI_API_KEY) e outras configuraÃ§Ãµes sensÃ­veis 
            sÃ£o carregadas de forma segura do arquivo .env
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    openai_key = os.getenv('OPENAI_API_KEY')
    api_status = "online" if openai_key else "offline"
    api_icon = "ğŸŸ¢" if openai_key else "ğŸ”´"
    
    st.markdown(f"""
    <div class="glass-card">
        <div style="display: flex; align-items: center; gap: 1rem;">
            <span style="font-size: 2rem;">{api_icon}</span>
            <div>
                <h4 style="margin: 0;">Status da API OpenAI</h4>
                <div class="status-indicator status-{api_status}">
                    â— {'Configurada' if openai_key else 'NÃ£o Configurada'}
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.code("OPENAI_API_KEY=sua_chave_openai_aqui", language="bash")
    
    with st.expander("ğŸ” Ver VariÃ¡veis de Ambiente (Debug)"):
        env_vars = {k: "********" if "KEY" in k or "TOKEN" in k else v for k, v in os.environ.items()}
        st.json(dict(list(env_vars.items())[:10]))  
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">ğŸš«</span>
        <h3 class="card-title">ExclusÃµes de Arquivos (.gitignore)</h3>
        <p class="card-subtitle">
            O arquivo .gitignore Ã© crucial para garantir que arquivos desnecessÃ¡rios, 
            temporÃ¡rios ou sensÃ­veis nÃ£o sejam incluÃ­dos no controle de versÃ£o
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("**ConteÃºdo sugerido para o seu arquivo `.gitignore`:**")
    st.code("""
# Ambiente Virtual
venv/
env/

# VariÃ¡veis de Ambiente
.env
.env.local

# Cache Python
__pycache__/
*.pyc
*.pyo
*.pyd

# Logs
logs/
*.log

# Banco de Dados
*.sqlite3
*.db

# Jupyter
.ipynb_checkpoints/

# Sistema
.DS_Store
.idea/
.vscode/

# Build
build/
dist/
*.egg-info/

# Testes
.pytest_cache/
.coverage

# TemporÃ¡rios
temp/
*.tmp
*.bak

# Chaves e Certificados
*.pem
*.key

# Arquivos do Projeto (Opcional)
uploaded_files/
chroma_db/
    """, language="bash")

    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">ğŸ’¾</span>
        <h3 class="card-title">Estrutura de Pastas do Projeto</h3>
        <p class="card-subtitle">
            Verifique se as seguintes pastas e arquivos estÃ£o organizados para 
            o funcionamento correto do sistema
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.code("""
ğŸ“ / (Raiz do Projeto)
â”œâ”€â”€ ğŸ“„ app.py (Script principal WhatsApp/Flask)
â”œâ”€â”€ ğŸ“„ streamlit_app.py (Interface Streamlit)
â”œâ”€â”€  .env (VariÃ¡veis de ambiente)
â”œâ”€â”€ ğŸ“„ .gitignore (ExclusÃµes Git)
â”œâ”€â”€ ğŸ“„ requirements.txt (DependÃªncias Python)
â”œâ”€â”€ ğŸ“ venv/ (Ambiente virtual Python)
â”œâ”€â”€ ğŸ“ chroma_db/ (Base de dados vetorial)
â”œâ”€â”€ ğŸ“ uploaded_files/ (Arquivos enviados)
â””â”€â”€ ğŸ“„ whatsapp_agent.log (Logs do sistema)
    """)

def logs_page():
    st.markdown('<h2 class="section-title fade-in">ğŸ“„ Logs do Sistema</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="glass-card fade-in">
        <p class="card-subtitle">
            Monitore as atividades e mensagens do seu Agente AI. Esta seÃ§Ã£o exibe 
            o conteÃºdo do arquivo whatsapp_agent.log, que Ã© gerado pelo seu script 
            de integraÃ§Ã£o do WhatsApp (app.py).
        </p>
    </div>
    """, unsafe_allow_html=True)

    log_file_path = "whatsapp_agent.log"

    if os.path.exists(log_file_path):
        file_size = os.path.getsize(log_file_path)
        file_modified = datetime.fromtimestamp(os.path.getmtime(log_file_path))
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            create_metric_card(f"{file_size} bytes", "Tamanho do Log", icon="ğŸ“Š")
        
        with col2:
            create_metric_card(file_modified.strftime("%H:%M"), "Ãšltima ModificaÃ§Ã£o", icon="ğŸ•")
        
        with col3:
            create_metric_card("Online", "Status do Log", icon="ğŸ“")
        
        st.markdown(f"""
        <div class="glass-card fade-in">
            <h3 class="card-title">ğŸ“‹ ConteÃºdo de {log_file_path}</h3>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            with open(log_file_path, "r", encoding="utf-8") as f:
                log_content = f.read()
                
            if len(log_content) > 10000:
                log_content = log_content[-10000:] + "\n\n[... mostrando apenas as Ãºltimas 10.000 caracteres]"
                
            st.code(log_content, language="text", height=400)
            
            st.download_button(
                label="ğŸ“¥ Baixar Log Completo",
                data=log_content,
                file_name=f"whatsapp_agent_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain"
            )
            
        except Exception as e:
            st.error(f"âŒ NÃ£o foi possÃ­vel ler o arquivo de log: {e}")
    else:
        st.markdown("""
        <div class="glass-card fade-in">
            <div style="text-align: center; padding: 2rem;">
                <span style="font-size: 4rem; display: block; margin-bottom: 1rem;">ğŸ“„</span>
                <h3 class="card-title">Arquivo de Log NÃ£o Encontrado</h3>
                <p class="card-subtitle">
                    O arquivo de log whatsapp_agent.log nÃ£o foi encontrado. 
                    Certifique-se de que o sistema de log do seu app.py esteja 
                    configurado para gravar eventos neste arquivo.
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="feature-card fade-in">
        <span class="feature-icon">ğŸ’¡</span>
        <h3 class="card-title">InformaÃ§Ãµes sobre Logging</h3>
        <p class="card-subtitle">
            Os logs sÃ£o ferramentas indispensÃ¡veis para depurar problemas, acompanhar 
            o fluxo de mensagens e monitorar o comportamento geral do agente em produÃ§Ã£o. 
            Ã‰ altamente recomendÃ¡vel configurar seu app.py para registrar eventos importantes.
        </p>
    </div>
    """, unsafe_allow_html=True)

# --- FunÃ§Ã£o Principal com NavegaÃ§Ã£o Melhorada ---
def main():
    st.markdown("""
    <div class="main-header fade-in">
        <h1 class="main-title">ğŸ¤– WhatsApp AI Agent</h1>
        <p class="main-subtitle">Sistema RAG Inteligente para Atendimento Automatizado</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.sidebar.markdown("""
    <div class="sidebar-header">
        <div class="sidebar-logo">ğŸ¤–</div>
        <h3 class="sidebar-title">WhatsApp AI</h3>
        <p class="sidebar-subtitle">Sistema RAG Inteligente</p>
    </div>
    """, unsafe_allow_html=True)
    
    pages = {
        "ğŸ  Dashboard": {"func": dashboard_page, "desc": "VisÃ£o geral do sistema"},
        "ğŸ“„ Documentos": {"func": documents_page, "desc": "Gerenciar base de conhecimento"},
        "ğŸ’¬ Chat RAG": {"func": rag_chat_page, "desc": "Testar sistema inteligente"},
        "ğŸ¤– ConfiguraÃ§Ã£o": {"func": agent_config_page, "desc": "Configurar agente IA"},
        "ğŸ“Š Analytics": {"func": analytics_page, "desc": "MÃ©tricas e relatÃ³rios"},
        "âš™ï¸ ConfiguraÃ§Ãµes": {"func": settings_page, "desc": "ConfiguraÃ§Ãµes do sistema"},
        "ğŸ“„ Logs": {"func": logs_page, "desc": "Monitorar atividades"}
    }

    selected_page = st.sidebar.radio(
        "NavegaÃ§Ã£o Principal:",
        list(pages.keys()),
        format_func=lambda x: x
    )
    
    st.sidebar.markdown(f"""
    <div style="background: rgba(255,255,255,0.1); padding: 1rem; border-radius: 12px; margin: 1rem 0;">
        <small style="color: rgba(255,255,255,0.8);">{pages[selected_page]['desc']}</small>
    </div>
    """, unsafe_allow_html=True)
    
    pages[selected_page]["func"]()

    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style="background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 16px;">
        <h4 style="color: white; margin: 0 0 0.5rem 0;">ğŸ‘¨â€ğŸ’» Ãlefe Lins</h4>
        <p style="color: rgba(255,255,255,0.8); font-size: 0.85rem; margin: 0;">
            Profissional intermediÃ¡rio em IA, focado em estudos e trabalho nas Ã¡reas 
            de marketing e tecnologia.
        </p>
        <div style="margin-top: 1rem; padding-top: 1rem; border-top: 1px solid rgba(255,255,255,0.2);">
            <p style="color: rgba(255,255,255,0.7); font-size: 0.8rem; margin: 0;">
                <strong>Objetivos:</strong> LanÃ§ar um aplicativo e iniciar um negÃ³cio de agentes de IA.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.sidebar.markdown("---")
    
    st.sidebar.markdown("""
    <div style="background: rgba(255,255,255,0.05); padding: 1rem; border-radius: 12px;">
        <h5 style="color: white; margin: 0 0 1rem 0;">ğŸš€ PrÃ³ximos Passos</h5>
        <ul style="color: rgba(255,255,255,0.8); font-size: 0.8rem; margin: 0; padding-left: 1rem;">
            <li>IntegraÃ§Ã£o completa RAG + WhatsApp</li>
            <li>Aprimoramento da interface UX/UI</li>
            <li>AutomaÃ§Ã£o de respostas inteligentes</li>
            <li>Sistema de analytics avanÃ§ado</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()