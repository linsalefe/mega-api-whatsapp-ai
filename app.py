#!/usr/bin/env python3
"""
WhatsApp AI Agent - Aplica√ß√£o principal
Integra√ß√£o com MEGA API para automa√ß√£o de WhatsApp
Refatorado com LangChain para gerenciamento de IA e mem√≥ria, AGORA COM SISTEMA RAG INTEGRADO.
"""

import os
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import logging
import threading

# LangChain Imports
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate

# RAG Imports
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.schema import Document

# --- IN√çCIO DAS CORRE√á√ïES DE ORDEM ---

# 1. Configura√ß√£o de Logging: DEVE SER O PRIMEIRO A SER CONFIGURADO
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler() # Sa√≠da para o console/logs do Render
        # Removido FileHandler por ser problem√°tico em ambientes sem persist√™ncia de disco
        # logging.FileHandler('whatsapp_agent.log'), # Para desenvolvimento local
    ]
)
logger = logging.getLogger(__name__)

# 2. Carregar vari√°veis de ambiente: ANTES DO USO DAS VARI√ÅVEIS
load_dotenv() # Para desenvolvimento local (carrega do .env se existir)

# 3. Inicializa√ß√£o do Flask App: ANTES DO USO DE app.config
app = Flask(__name__)

# 4. Vari√°veis de Ambiente e SECRET_KEY: CARREGADAS ANTES DE SEREM USADAS
SECRET_KEY = os.getenv('SECRET_KEY')
MEGA_API_BASE_URL = os.getenv('MEGA_API_BASE_URL')
MEGA_API_TOKEN = os.getenv('MEGA_API_TOKEN')
MEGA_INSTANCE_ID = os.getenv('MEGA_INSTANCE_ID')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Atribui SECRET_KEY √† configura√ß√£o do Flask
app.config['SECRET_KEY'] = SECRET_KEY if SECRET_KEY else 'fallback-secret-key-for-development' # fallback para dev

# Debug das vari√°veis de ambiente: AGORA logger EST√Å DEFINIDO
logger.info(f"üîç Debug - SECRET_KEY: {'***' if SECRET_KEY else 'None'}")
logger.info(f"üîç Debug - MEGA_API_BASE_URL: {MEGA_API_BASE_URL}")
logger.info(f"üîç Debug - MEGA_API_TOKEN: {'***' if MEGA_API_TOKEN else 'None'}")
logger.info(f"üîç Debug - MEGA_INSTANCE_ID: {MEGA_INSTANCE_ID}")
logger.info(f"üîç Debug - OPENAI_API_KEY: {'***' if OPENAI_API_KEY else 'None'}")

# Valida√ß√£o das vari√°veis essenciais: AP√ìS CARREGAMENTO
required_vars = {
    'SECRET_KEY': SECRET_KEY, # Adicionado para valida√ß√£o
    'MEGA_API_BASE_URL': MEGA_API_BASE_URL,
    'MEGA_API_TOKEN': MEGA_API_TOKEN,
    'MEGA_INSTANCE_ID': MEGA_INSTANCE_ID,
    'OPENAI_API_KEY': OPENAI_API_KEY
}

missing_vars = [var for var, value in required_vars.items() if not value]

if missing_vars:
    logger.error(f"‚ùå Vari√°veis de ambiente obrigat√≥rias n√£o encontradas: {missing_vars}")
    logger.error("Certifique-se de que todas as vari√°veis essenciais est√£o configuradas corretamente.")
    exit(1)

# --- FIM DAS CORRE√á√ïES DE ORDEM INICIAIS ---


# --- IN√çCIO DA CONFIGURA√á√ÉO DO LANGCHAIN E RAG: MOVIDO PARA CIMA ---

# Configura√ß√£o do LangChain LLM (ChatOpenAI)
llm = ChatOpenAI(
    api_key=OPENAI_API_KEY,
    model="gpt-3.5-turbo", # Ou "gpt-4" se preferir e tiver acesso
    temperature=0.7 # Criatividade da resposta
)

# Template de prompt personalizado para a IA (original, para fallback e conversa√ß√£o geral)
prompt_template = PromptTemplate(
    input_variables=["history", "input"],
    template="""Voc√™ √© um assistente de IA amig√°vel e prestativo, especializado em marketing e tecnologia,
focado em ajudar √Ålefe Lins a desenvolver um aplicativo e iniciar um neg√≥cio de agentes de IA.
Responda de forma elaborada e forne√ßa exemplos quando apropriado.
Seu conhecimento base √© at√© Mar√ßo de 2025.

Hist√≥rico da Conversa:
{history}
Usu√°rio: {input}
Assistente:"""
)

# Dicion√°rio para armazenar mem√≥rias por usu√°rio
user_memories = {}

def get_user_memory(user_id):
    """Obt√©m ou cria uma mem√≥ria para o usu√°rio espec√≠fico"""
    if user_id not in user_memories:
        user_memories[user_id] = ConversationBufferMemory(
            memory_key="history",
            return_messages=False # Mantenha como False para compatibilidade com o prompt_template
        )
        logger.info(f"Nova mem√≥ria criada para o usu√°rio: {user_id}")
    return user_memories[user_id]

# NOVO: Configura√ß√£o do Sistema RAG (ChromaDB)
PERSIST_DIRECTORY = "./chroma_db"
RAG_ENABLED = False # Come√ßa desativado, tenta carregar o ChromaDB
rag_chain = None # Inicializa rag_chain como None
vectorstore = None # Inicializa vectorstore como None para escopo global

try:
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=OPENAI_API_KEY)

    if os.path.exists(PERSIST_DIRECTORY) and os.listdir(PERSIST_DIRECTORY):
        vectorstore = Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=embeddings
        )
        logger.info("‚úÖ ChromaDB carregado com sucesso!")

        try:
            collection = vectorstore._collection
            doc_count = collection.count()
            logger.info(f"üìö Base de conhecimento: {doc_count} documentos carregados.")
        except Exception as e:
            doc_count = 0
            logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel obter a contagem de documentos do ChromaDB: {e}")

        if doc_count > 0:
            retriever = vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3} # Recupera os 3 chunks mais relevantes
            )
            rag_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=retriever,
                return_source_documents=True
            )
            RAG_ENABLED = True
            logger.info("üß† Sistema RAG ativado e pronto!")
        else:
            logger.warning("‚ö†Ô∏è ChromaDB existe, mas est√° vazio. RAG desativado.")
    else:
        logger.warning("‚ö†Ô∏è Nenhuma base de conhecimento (chroma_db) encontrada. RAG desativado. Por favor, crie uma via Streamlit.")

except Exception as e:
    logger.error(f"‚ùå Erro ao inicializar ChromaDB: {e}", exc_info=True)
    RAG_ENABLED = False
    rag_chain = None

# --- FIM DA CONFIGURA√á√ÉO DO LANGCHAIN E RAG ---

# --- FUN√á√ïES AUXILIARES: ORDEM MANTIDA COMO NO SEU C√ìDIGO ---

def generate_ai_response(message_text: str, user_id: str) -> str:
    """
    Gera uma resposta da IA usando o LangChain.
    Prioriza o sistema RAG se ativado e houver contexto relevante.
    Caso contr√°rio, usa a cadeia de conversa√ß√£o padr√£o.
    """
    try:
        logger.info(f"Gerando resposta IA para a mensagem de '{user_id}': '{message_text[:100]}...'")

        memory = get_user_memory(user_id) # Obter mem√≥ria espec√≠fica do usu√°rio
        final_response = ""
        used_rag = False # Flag para saber se o RAG foi a fonte da resposta

        # --- 1. Tentar responder com RAG ---
        if RAG_ENABLED and rag_chain:
            try:
                logger.info(f"üìñ Tentando recuperar informa√ß√µes da base de conhecimento para '{user_id}'...")
                rag_result = rag_chain.invoke({"query": message_text})

                rag_answer = rag_result.get("result", "")
                sources = rag_result.get("source_documents", [])

                # Crit√©rio para decidir se a resposta RAG √© "√∫til"
                # Uma resposta √© considerada √∫til se houver fontes e a resposta n√£o for gen√©rica de "n√£o encontrei"
                if sources and len(rag_answer) > 50 and "n√£o encontrei informa√ß√µes" not in rag_answer.lower() and "n√£o consigo responder" not in rag_answer.lower():
                    final_response = rag_answer
                    used_rag = True
                    logger.info(f"üìñ RAG encontrou {len(sources)} documentos relevantes e gerou uma resposta √∫til: '{final_response[:100]}...'")
                else:
                    logger.info("‚ö†Ô∏è RAG ativado, mas nenhum documento relevante ou resposta √∫til encontrada para esta consulta.")
            except Exception as e:
                logger.error(f"Erro na consulta RAG para '{user_id}': {e}", exc_info=True)
                logger.info("‚ö†Ô∏è Falha na consulta RAG. Prosseguindo para conversa√ß√£o padr√£o.")
        else:
            logger.info("‚ùå Sistema RAG desativado ou n√£o inicializado. Prosseguindo para conversa√ß√£o padr√£o.")

        # --- 2. Se RAG n√£o gerou uma resposta √∫til, usar a ConversationChain padr√£o ---
        if not final_response:
            logger.info("üí¨ Usando ConversationChain padr√£o para gerar resposta.")
            # A ConversationChain j√° gerencia a mem√≥ria automaticamente com o prompt_template padr√£o.
            conversation_chain_instance = ConversationChain( # Renomeado para evitar conflito com 'conversation' global se definido
                llm=llm,
                memory=memory,
                prompt=prompt_template, # Usa o prompt_template original (apenas history e input)
                verbose=True
            )
            final_response = conversation_chain_instance.predict(input=message_text)

        # --- 3. Atualizar mem√≥ria manualmente se a resposta veio do RAG ---
        # Se a resposta final veio do RAG (e n√£o da ConversationChain), precisamos adicionar
        # a intera√ß√£o (input do usu√°rio e output do RAG) √† mem√≥ria para manter o hist√≥rico.
        # A ConversationChain.predict() j√° faz isso automaticamente.
        if used_rag:
            memory.save_context({"input": message_text}, {"output": final_response})
            logger.info("Mem√≥ria atualizada manualmente com entrada e sa√≠da RAG para manter hist√≥rico.")

        logger.info(f"Resposta da IA gerada para '{user_id}': '{final_response[:100]}...'")
        return final_response

    except Exception as e:
        logger.error(f"Erro ao gerar resposta da IA para '{user_id}': {e}", exc_info=True)
        return "Desculpe, n√£o consegui gerar uma resposta no momento. Por favor, tente novamente mais tarde."

def send_whatsapp_message(phone_number: str, message: str) -> bool:
    """
    Envia uma mensagem de texto para um n√∫mero de WhatsApp via MEGA API.
    """
    try:
        # CONSTRU√á√ÉO DA URL CORRETA COM BASE NA DOCUMENTA√á√ÉO (SUA ORIGINAL)
        url = f"{MEGA_API_BASE_URL}/rest/sendMessage/{MEGA_INSTANCE_ID}/text"

        headers = {
            'Authorization': f'Bearer {MEGA_API_TOKEN}',
            'Content-Type': 'application/json'
        }

        formatted_phone_number = phone_number
        if not ("@s.whatsapp.net" in phone_number or "@g.us" in phone_number):
             formatted_phone_number = f"{phone_number}@s.whatsapp.net"

        payload = {
            "messageData": {
                "to": formatted_phone_number,
                "text": message
            }
        }

        logger.info(f"Tentando enviar mensagem para {formatted_phone_number} via MEGA API (URL: {url})")
        logger.debug(f"Payload: {payload}")
        response = requests.post(url, json=payload, headers=headers, timeout=15)

        response.raise_for_status()

        response_json = response.json()
        if response_json.get('error'):
            logger.error(f"MEGA API reportou erro no corpo da resposta para {formatted_phone_number}: {response_json.get('message', 'Erro desconhecido da API')}. Resposta completa: {response_json}")
            return False

        logger.info(f"Mensagem enviada com sucesso para {formatted_phone_number}. Status HTTP: {response.status_code}, Resposta da API: {response_json}")
        return True

    except requests.exceptions.RequestException as e:
        logger.error(f"Erro de requisi√ß√£o ao enviar mensagem para {phone_number} via MEGA API: {e}", exc_info=True)
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"Resposta de erro da API: {e.response.text}")
        return False
    except Exception as e:
        logger.error(f"Erro inesperado ao enviar mensagem via MEGA API: {e}", exc_info=True)
        return False

def process_message_async(phone_full_jid: str, message_text: str, sender_name: str):
    """
    Fun√ß√£o ass√≠ncrona para processar a mensagem do usu√°rio, gerar a resposta da IA e envi√°-la.
    Executada em uma thread separada para n√£o bloquear o webhook principal.
    """
    try:
        logger.info(f"Iniciando processamento ass√≠ncrono da mensagem de {sender_name} ({phone_full_jid}).")

        user_id_for_memory = phone_full_jid.replace('@s.whatsapp.net', '').replace('@g.us', '')

        # 1. Gerar resposta com IA (que agora lida com RAG internamente)
        ai_response = generate_ai_response(message_text, user_id_for_memory)

        # 2. Enviar resposta de volta ao usu√°rio via MEGA API
        success = send_whatsapp_message(phone_full_jid, ai_response)

        if success:
            logger.info(f"‚úÖ Resposta da IA enviada com sucesso para {phone_full_jid}.")
        else:
            logger.error(f"‚ùå Falha ao enviar a resposta da IA para {phone_full_jid}.")

    except Exception as e:
        logger.error(f"Erro no processamento ass√≠ncrono da mensagem: {e}", exc_info=True)

def process_webhook_async_corrected_for_logs(data):
    """
    Processa webhook de forma ass√≠ncrona. Esta vers√£o √© mais robusta
    na forma como extrai os dados do payload da MEGA API.
    Utilizada para fins de depura√ß√£o e compatibilidade com logs anteriores.
    """
    try:
        message_type = data.get('messageType')
        message_content = None

        if message_type == 'conversation':
            message_content = data.get('message', {}).get('conversation')
        elif message_type == 'textMessage':
            message_content = data.get('message', {}).get('text')

        is_from_me = data.get('key', {}).get('fromMe', False)

        if not message_content or is_from_me:
            logger.info(f"Webhook (process_webhook_async_corrected_for_logs) ignorado (messageType: {message_type}, fromMe: {is_from_me}, hasContent: {bool(message_content)})")
            return

        sender_full_jid = data.get('key', {}).get('remoteJid', '')
        sender_name = data.get('pushName', 'Usu√°rio')

        if not sender_full_jid:
            logger.warning("JID do remetente n√£o encontrado no webhook.")
            return

        user_id_for_memory = sender_full_jid.replace('@s.whatsapp.net', '').replace('@g.us', '')

        logger.info(f"Processando mensagem (process_webhook_async_corrected_for_logs) de {sender_name} ({user_id_for_memory}): '{message_content}'")

        ai_response = generate_ai_response(message_content, user_id_for_memory)

        success = send_whatsapp_message(sender_full_jid, ai_response)

        if success:
            logger.info(f"‚úÖ Resposta da IA enviada com sucesso para {sender_full_jid}.")
        else:
            logger.error(f"‚ùå Falha ao enviar a resposta da IA para {sender_full_jid}.")

    except Exception as e:
        logger.error(f"Erro no processamento ass√≠ncrono do webhook (process_webhook_async_corrected_for_logs): {e}", exc_info=True)

# --- FIM DAS FUN√á√ïES AUXILIARES ---


# --- ROTAS DA API: ORDEM MANTIDA COMO NO SEU C√ìDIGO ---

@app.route('/')
def home():
    """Endpoint de teste para verificar se o Flask est√° rodando."""
    doc_count = 0
    # A vari√°vel vectorstore agora √© global e deveria estar acess√≠vel aqui
    if RAG_ENABLED and vectorstore: # Verifica se vectorstore foi inicializado com sucesso
        try:
            collection = vectorstore._collection
            doc_count = collection.count()
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel obter a contagem de documentos para o endpoint home: {e}")
            doc_count = "unknown"

    # A data e hora devem ser geradas dinamicamente
    import datetime
    now_utc = datetime.datetime.now(datetime.timezone.utc)
    now_brt = now_utc - datetime.timedelta(hours=3) # Bras√≠lia Time is UTC-3

    return jsonify({
        "status": "success",
        "message": "WhatsApp AI Agent est√° rodando!",
        "version": "1.0",
        "rag_enabled": RAG_ENABLED,
        "documents_in_chromadb": doc_count,
        "current_time_utc": now_utc.strftime("%d/%m/%Y %H:%M:%S (UTC)"),
        "current_time_bras√≠lia": now_brt.strftime("%d/%m/%Y %H:%M:%S (UTC-3)")
    })

@app.route('/webhook', methods=['POST'])
def webhook():
    """
    Endpoint principal para receber notifica√ß√µes (webhooks) da MEGA API.
    """
    try:
        data = request.get_json()
        if data is None:
            logger.warning("Webhook recebido sem dados JSON.")
            return jsonify({"status": "error", "message": "No JSON data"}), 400

        logger.info(f"Webhook recebido: {data}")

        if (data and
            data.get('messageType') == 'conversation' and
            data.get('message', {}).get('conversation') and
            data.get('key', {}).get('remoteJid') and
            not data.get('key', {}).get('fromMe', False)):

            phone_full_jid = data['key']['remoteJid']
            message_text = data['message']['conversation']
            sender_name = data.get('pushName', 'Usu√°rio')

            logger.info(f"Mensagem de texto v√°lida recebida de {sender_name} ({phone_full_jid}): '{message_text}'")

            thread = threading.Thread(
                target=process_message_async,
                args=(phone_full_jid, message_text, sender_name)
            )
            thread.start()

            return jsonify({"status": "received", "message": "Mensagem recebida e em processamento"}), 200

        else:
            logger.info(f"Webhook ignorado (n√£o √© uma mensagem de texto para processamento de IA ou √© uma mensagem pr√≥pria): {data.get('messageType', 'Tipo Desconhecido')}")
            return jsonify({"status": "ignored", "message": "Payload n√£o √© uma mensagem de texto para processamento de IA ou √© uma mensagem pr√≥pria."}), 200

    except Exception as e:
        logger.error(f"Erro inesperado no webhook: {e}", exc_info=True)
        return jsonify({"status": "error", "message": "Erro interno no servidor de webhook."}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """
    Endpoint para verifica√ß√£o de sa√∫de da aplica√ß√£o e conectividade com a MEGA API.
    """
    mega_api_status = "disconnected"
    mega_api_response_detail = "N/A"
    try:
        test_url = f"{MEGA_API_BASE_URL}/rest/instance/{MEGA_INSTANCE_ID}/status"
        headers = {
            'Authorization': f'Bearer {MEGA_API_TOKEN}'
        }
        response = requests.get(test_url, headers=headers, timeout=5)
        if response.status_code == 200:
            mega_api_status = "connected"
            mega_api_response_detail = response.json()
        else:
            mega_api_status = f"connected (HTTP {response.status_code})"
            mega_api_response_detail = response.text
            logger.warning(f"MEGA API acess√≠vel, mas retornou status: {response.status_code} no health check. Resposta: {response.text}")
    except requests.exceptions.RequestException as e:
        mega_api_status = "error"
        mega_api_response_detail = str(e)
        logger.error(f"Falha ao conectar com MEGA API durante o health check: {e}", exc_info=True)

    doc_count = 0
    if RAG_ENABLED and vectorstore: # Usando vectorstore que √© global
        try:
            collection = vectorstore._collection
            doc_count = collection.count()
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel obter a contagem de documentos para o health check: {e}")
            doc_count = "unknown"

    return jsonify({
        "status": "healthy",
        "flask_app": "running",
        "mega_api_connectivity": mega_api_status,
        "mega_api_response_detail": mega_api_response_detail,
        "rag_enabled": RAG_ENABLED,
        "documents_in_chromadb": doc_count
    })

@app.route('/test_mega_api_send', methods=['POST'])
def test_mega_api_send():
    """
    Endpoint de teste para enviar uma mensagem via MEGA API manualmente.
    √ötil para depurar o envio.
    """
    data = request.get_json()
    test_phone = data.get('phone')
    test_message = data.get('message')

    if not test_phone or not test_message:
        return jsonify({"status": "error", "message": "Par√¢metros 'phone' e 'message' s√£o obrigat√≥rios"}), 400

    logger.info(f"Recebida requisi√ß√£o de teste de envio para {test_phone} com mensagem: {test_message}")

    if not ("@s.whatsapp.net" in test_phone or "@g.us" in test_phone):
        test_phone_formatted = f"{test_phone}@s.whatsapp.net"
    else:
        test_phone_formatted = test_phone

    success = send_whatsapp_message(test_phone_formatted, test_message)

    if success:
        return jsonify({"status": "success", "message": f"Mensagem de teste enviada para {test_phone}"}), 200
    else:
        return jsonify({"status": "error", "message": f"Falha ao enviar mensagem de teste para {test_phone}"}), 500

# --- FIM DAS ROTAS DA API ---

# --- MAIN EXECUTION BLOCK ---
if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'

    logger.info(f"Iniciando WhatsApp AI Agent na porta {port} (Debug: {debug})")
    # RAG_ENABLED AGORA EST√Å DEFINIDO GLOBALMENTE E PODE SER USADO AQUI
    logger.info(f"üß† Sistema RAG: {'‚úÖ Ativado' if RAG_ENABLED else '‚ùå Desativado'}")
    app.run(host='0.0.0.0', port=port, debug=debug)